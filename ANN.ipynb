{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader # for dealing with data\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim # Optimization package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "nswre74_control = pd.read_excel('/Users/mawuliagamah/gitprojects/causal_inference/causal_inference/datasets/nswre74_control.xls')\n",
    "nswre74_treated = pd.read_excel('/Users/mawuliagamah/gitprojects/causal_inference/causal_inference/nswre74_treated.xlsx')\n",
    "nswre74 = pd.concat([nswre74_control,nswre74_treated])\n",
    "\n",
    "\n",
    "nswre74_shuffled = nswre74.sample(frac=1)\n",
    "nswre74_shuffled.shape\n",
    "# Train and test split\n",
    "nswre74_train = nswre74_shuffled.iloc[0:356]\n",
    "nswre74_test = nswre74_shuffled.iloc[357:len(nswre74)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 9 # Variables within dataset \n",
    "hidden_dim = 2 # hidden layers\n",
    "output_dim= 2    # number of classes\n",
    "\n",
    "\n",
    "# Convert features to tensor \n",
    "age_array = np.asarray(nswre74_train['age'])\n",
    "education_array= np.asarray(nswre74_train['education'])\n",
    "black_array = np.asarray(nswre74_train['black'])\n",
    "hispanic_array = np.asarray(nswre74_train['hispanic'])\n",
    "nodegree_array = np.asarray(nswre74_train['nodegree'])\n",
    "re74_array = np.asarray(nswre74_train['re74'])\n",
    "re75_array = np.asarray(nswre74_train['re75'])\n",
    "re78_array = np.asarray(nswre74_train['re78'])\n",
    "\n",
    "features_arrray = [age_array,education_array,black_array,hispanic_array,nodegree_array,re74_array,re75_array,re78_array]\n",
    "features_arrray = np.transpose(features_arrray)\n",
    "X = torch.Tensor(features_arrray)\n",
    "\n",
    "#Convert target to tensor \n",
    "targets = nswre74_train['treat']\n",
    "Y = torch.tensor(targets.values)\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "X = flatten(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define neural netowrk class \n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #Neural net input layer ,  356 input layers, to 15 hidden neurons\n",
    "            nn.Linear(8,356),\n",
    "            #relu activation function for hidden layer 1\n",
    "            nn.ReLU(),\n",
    "            #relu activation function for hidden layer 2\n",
    "            nn.Linear(356, 356),\n",
    "            nn.ReLU(),\n",
    "            #Output layer \n",
    "            #nn.Linear(356, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork() #Initialise model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=356, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=356, out_features=356, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=356, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##     Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(X, Y)\n",
    "trainloader = DataLoader(train, batch_size=1, shuffle=False)\n",
    "\n",
    "number_of_epochs = 3\n",
    "learning_rate = 1e-5\n",
    "max_iterations = 200\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.LBFGS(model.parameters(),  lr=learning_rate , max_iter=max_iterations ) \n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE) # slight difference: we optimize w.r.t. the net parameters now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'closure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mawuliagamah/Desktop/scrapbook.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mawuliagamah/Desktop/scrapbook.ipynb#ch0000007?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mawuliagamah/Desktop/scrapbook.ipynb#ch0000007?line=15'>16</a>\u001b[0m \u001b[39m# Adjust learning weights\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mawuliagamah/Desktop/scrapbook.ipynb#ch0000007?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mawuliagamah/Desktop/scrapbook.ipynb#ch0000007?line=17'>18</a>\u001b[0m \u001b[39m# Gather data and report\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mawuliagamah/Desktop/scrapbook.ipynb#ch0000007?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m----------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'closure'"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loader_iter = iter(trainloader)\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader_iter):\n",
    "       \n",
    "        # Zero gradients for batch \n",
    "        model.zero_grad() \n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = X, Y\n",
    "        # Make predictions for given batch \n",
    "        output = model(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Output (UPDATE: Epoch #\" + str(epoch + 1) + \", Batch #\" + str(batch_idx + 1) + \"):\")\n",
    "        #print(net(X)) # much better!\n",
    "\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> cps1 match </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650093</td>\n",
       "      <td>-0.186797</td>\n",
       "      <td>-1.562804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.975693</td>\n",
       "      <td>49.208115</td>\n",
       "      <td>-101.912224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608929</td>\n",
       "      <td>-0.178376</td>\n",
       "      <td>-1.435403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.270592</td>\n",
       "      <td>42.628761</td>\n",
       "      <td>-88.470245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.578587</td>\n",
       "      <td>46.778503</td>\n",
       "      <td>-96.860901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.510414</td>\n",
       "      <td>-0.128720</td>\n",
       "      <td>-1.459245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.712492</td>\n",
       "      <td>-0.204728</td>\n",
       "      <td>-1.707634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>40.331329</td>\n",
       "      <td>39.695103</td>\n",
       "      <td>-82.205582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1.220890</td>\n",
       "      <td>-0.427712</td>\n",
       "      <td>-2.055882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>22.693027</td>\n",
       "      <td>22.271854</td>\n",
       "      <td>-45.880962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1           2\n",
       "0     0.650093  -0.186797   -1.562804\n",
       "1    49.975693  49.208115 -101.912224\n",
       "2     0.608929  -0.178376   -1.435403\n",
       "3    43.270592  42.628761  -88.470245\n",
       "4    47.578587  46.778503  -96.860901\n",
       "..         ...        ...         ...\n",
       "351   0.510414  -0.128720   -1.459245\n",
       "352   0.712492  -0.204728   -1.707634\n",
       "353  40.331329  39.695103  -82.205582\n",
       "354   1.220890  -0.427712   -2.055882\n",
       "355  22.693027  22.271854  -45.880962\n",
       "\n",
       "[356 rows x 3 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44a7c5cf9512a4ad670122a007d348488b56f79d3796a47615dc74da9f36a764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
